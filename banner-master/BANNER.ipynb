{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-pretrained-bert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo_hiecYZqA-",
        "outputId": "41251e11-9c41-4629-86e9-2f47aaf92311"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-pretrained-bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/123.8 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m122.9/123.8 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (1.21.6)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.54-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (2.25.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.4.0)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting botocore<1.30.0,>=1.29.54\n",
            "  Downloading botocore-1.29.54-py3-none-any.whl (10.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-pretrained-bert) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-pretrained-bert) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.30.0,>=1.29.54->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.54->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed boto3-1.26.54 botocore-1.29.54 jmespath-1.0.1 pytorch-pretrained-bert-0.6.2 s3transfer-0.6.0 urllib3-1.26.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/banner-master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCcIEUiCZtKW",
        "outputId": "06e19075-dfc9-4880-8f3c-8622695e754d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1-_YhZjR5RRUfyhjAlT-wbLioqxzpdA46/banner-master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4P3mJ__20bE",
        "outputId": "962aa84b-b000-48c7-d0b3-f5d19322543b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cost.py  dataset.py    methodology.jpg\tpred_labels_banner.txt\tREADME.md\n",
            "crf.py\t inference.py  models\t\tpred_labels.txt\t\trun.py\n",
            "data\t main.py       net.py\t\t__pycache__\t\ttrainer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT-sDKw7ybtb",
        "outputId": "fef1eaa1-79ad-4948-bfd1-b4bbb6b27056"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import json\n",
        "from trainer import train,eval\n",
        "from cost import crit_weights_gen\n",
        "from net import Net\n",
        "from dataset import NerDataset, pad, VOCAB, tag2idx, idx2tag\n",
        "import dataset\n",
        "import torch.optim as optim\n",
        "import os\n",
        "\n",
        "# dataset.VOCAB = ('<PAD>', 'O',\n",
        "# 'I-GRP',\n",
        "# 'B-PROD',\n",
        "# 'I-PER',\n",
        "# 'I-CW',\n",
        "# 'I-CORP',\n",
        "# 'B-PER',\n",
        "# 'B-CORP',\n",
        "# 'B-GRP',\n",
        "# 'B-LOC',\n",
        "# 'B-CW',\n",
        "# 'I-PROD',\n",
        "# 'I-LOC')\n",
        "#\n",
        "# dataset.tag2idx = {tag: idx for idx, tag in enumerate(VOCAB)}\n",
        "# dataset.idx2tag = {idx: tag for idx, tag in enumerate(VOCAB)}\n",
        "\n",
        "print(dataset.VOCAB)\n",
        "\n",
        "batch_size = 32\n",
        "lr = 0.001\n",
        "n_epochs = 20\n",
        "finetuning = True\n",
        "top_rnns = True\n",
        "trainset = \"data/train.jsonl\"\n",
        "testset = \"data/test.jsonl\"\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = Net(top_rnns, len(VOCAB), device, finetuning)\n",
        "#model.load_state_dict(torch.load('models/banner_model.pt'))\n",
        "model.to(device)\n",
        "\n",
        "# with open(trainset) as infile:\n",
        "#     data = json.load(infile)\n",
        "\n",
        "data = []\n",
        "for line in open(trainset, 'r', encoding=\"utf8\"):\n",
        "    data.append(json.loads(line))\n",
        "\n",
        "new = data\n",
        "train_texts, train_labels = list(zip(*map(lambda d: (d['tokens'], d['tags']), new)))\n",
        "\n",
        "sents_train, tags_li_train = [], []\n",
        "for x in train_texts:\n",
        "    sents_train.append([\"[CLS]\"] + x + [\"[SEP]\"])\n",
        "for y in train_labels:\n",
        "    tags_li_train.append([\"<PAD>\"] + y + [\"<PAD>\"])\n",
        "\n",
        "train_dataset = NerDataset(sents_train, tags_li_train)\n",
        "\n",
        "train_iter = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                             batch_size= batch_size,\n",
        "                             shuffle=True,\n",
        "                             collate_fn=pad,\n",
        "                             num_workers=0\n",
        "                             )\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
        "# data_dist = [7237, 15684, 714867, 759, 20815, 9662, 8512, 37529, 70025]\n",
        "# crit_weights = crit_weights_gen(0.5,0.9,data_dist)\n",
        "#insert 0 cost for ignoring <PAD>\n",
        "# crit_weights.insert(0,0)\n",
        "# crit_weights = torch.tensor(crit_weights).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s9vTgIrdD4S",
        "outputId": "2500f6cc-6eda-4e3b-c918-433d19bd022d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 995526/995526 [00:00<00:00, 4207706.60B/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('<PAD>', 'O', 'I-GRP', 'B-PROD', 'I-PER', 'I-CW', 'I-CORP', 'B-PER', 'B-CORP', 'B-GRP', 'B-LOC', 'B-CW', 'I-PROD', 'I-LOC')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 662804195/662804195 [00:10<00:00, 60501339.07B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aFQDcLU4ejEY",
        "outputId": "f1d851dd-a59d-423b-da9b-69e41cdb9152"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for line in open(testset, 'r', encoding=\"utf8\"):\n",
        "    data.append(json.loads(line))\n",
        "\n",
        "new = data\n",
        "test_texts, test_labels = list(zip(*map(lambda d: (d['tokens'], d['tags']), new)))\n",
        "\n",
        "sents_test, tags_li_test = [], []\n",
        "for x in test_texts:\n",
        "    sents_test.append([\"[CLS]\"] + x + [\"[SEP]\"])\n",
        "for y in test_labels:\n",
        "    tags_li_test.append([\"<PAD>\"] + y + [\"<PAD>\"])\n",
        "\n",
        "test_dataset = NerDataset(sents_test, tags_li_test)\n",
        "\n",
        "test_iter = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                             batch_size=batch_size,\n",
        "                             shuffle=False,\n",
        "                             collate_fn = pad,\n",
        "                             num_workers=0\n",
        "                             )"
      ],
      "metadata": {
        "id": "Aq3b4BaTR_6h"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, n_epochs+1):\n",
        "    if epoch>10:\n",
        "        optimizer = optim.Adam([\n",
        "                                {\"params\": model.fc.parameters(), \"lr\": 0.0005},\n",
        "                                {\"params\": model.bert.parameters(), \"lr\": 5e-5},\n",
        "                                {\"params\": model.rnn.parameters(), \"lr\": 0.0005},\n",
        "                                {\"params\": model.crf.parameters(), \"lr\": 0.0005}\n",
        "                                ],)\n",
        "    train(model, train_iter, optimizer, criterion, epoch)\n",
        "    # pred = eval(model, test_iter, epoch)\n",
        "\n",
        "    fname = os.path.join(\"models\", str(epoch))\n",
        "    torch.save(model.state_dict(), f\"{fname}.pt\")\n",
        "\n",
        "\n",
        "# pred = eval(model, test_iter)\n",
        "# for x in range(len(pred[0])):\n",
        "#     if pred[0][x] == '<PAD>':\n",
        "#         pred[0][x] = 'O'\n",
        "\n",
        "# all_preds = sents_test[0][1:-1],pred[0][1:-1]"
      ],
      "metadata": {
        "id": "Wdg_ZStv4Jex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-1nbi2ccI9t",
        "outputId": "777fe9bf-08e3-4b65-beb0-ae904d1a1efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = Net(top_rnns, len(VOCAB), device, finetuning)\n",
        "model.load_state_dict(torch.load('models/20.pt'))\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "JXjqFHT9bICL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = eval(model, test_iter)"
      ],
      "metadata": {
        "id": "ooaBeHFF0chs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred)"
      ],
      "metadata": {
        "id": "x_goU_M9zxg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ggtQZx6i0ba3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds = []\n",
        "for x in range(len(pred)):\n",
        "    if pred[x][0] == '<PAD>':\n",
        "      pred[x][0] = 'O'\n",
        "    # all_preds.append((sents_test[x][1:-1],pred[x][1:-1]))\n",
        "    all_preds.append(pred[x][1:-1])"
      ],
      "metadata": {
        "id": "l7103qz3l8ti"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds"
      ],
      "metadata": {
        "id": "PG_Y1WYuz36V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('pred_labels_banner.txt', 'w') as f:\n",
        "  for sentence_pred in all_preds:\n",
        "    for pred in sentence_pred:\n",
        "      f.write(pred+'\\n')\n",
        "    f.write('\\n')"
      ],
      "metadata": {
        "id": "XGg9XtlIVZSn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQu-oxhAYyQ7",
        "outputId": "d95ea2ab-43c8-4701-d55a-22a7cf081afa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cost.py  dataset.py    methodology.jpg\tpred_labels_banner.txt\tREADME.md\n",
            "crf.py\t inference.py  models\t\tpred_labels.txt\t\trun.py\n",
            "data\t main.py       net.py\t\t__pycache__\t\ttrainer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGC3YhyFn-8c",
        "outputId": "19458a90-2092-4ce0-e5a8-5582659e496c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cost.py  dataset.py    methodology.jpg\tpred_labels_banner.txt\tREADME.md\n",
            "crf.py\t inference.py  models\t\tpred_labels.txt\t\trun.py\n",
            "data\t main.py       net.py\t\t__pycache__\t\ttrainer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8QLtZX5iZV4Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}